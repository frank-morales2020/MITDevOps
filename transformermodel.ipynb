{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "history_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOikx7OKNFwLuoW0c8wrMZ7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/MITDevOps/blob/master/transformermodel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgEESGdGb-k5",
        "outputId": "93d96dfd-a4f2-433c-b3de-7ceb4dd5bbb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/tools\n",
            "/content\n",
            "\n",
            "Start of epoch 1\n",
            "Epoch 1 Step 0 Loss 8.5324 Accuracy 0.0000\n",
            "Epoch 1 Step 50 Loss 1075.9822 Accuracy 0.0218\n",
            "Epoch 1 Step 100 Loss 1306.7518 Accuracy 0.0217\n",
            "Epoch 1: Training Loss 1365.7739, Training Accuracy 0.0237\n",
            "\n",
            "Start of epoch 2\n",
            "Epoch 2 Step 0 Loss 1172.6812 Accuracy 0.0496\n",
            "Epoch 2 Step 50 Loss 1729.9301 Accuracy 0.0296\n",
            "Epoch 2 Step 100 Loss 1704.9773 Accuracy 0.0302\n",
            "Epoch 2: Training Loss 1766.4779, Training Accuracy 0.0303\n",
            "\n",
            "Start of epoch 3\n",
            "Epoch 3 Step 0 Loss 1587.5691 Accuracy 0.0319\n",
            "Epoch 3 Step 50 Loss 1935.9569 Accuracy 0.0306\n",
            "Epoch 3 Step 100 Loss 1968.1316 Accuracy 0.0329\n",
            "Epoch 3: Training Loss 1985.0201, Training Accuracy 0.0340\n",
            "\n",
            "Start of epoch 4\n",
            "Epoch 4 Step 0 Loss 2109.9963 Accuracy 0.0284\n",
            "Epoch 4 Step 50 Loss 1749.2297 Accuracy 0.0421\n",
            "Epoch 4 Step 100 Loss 1821.7087 Accuracy 0.0411\n",
            "Epoch 4: Training Loss 1893.7070, Training Accuracy 0.0410\n",
            "\n",
            "Start of epoch 5\n",
            "Epoch 5 Step 0 Loss 2439.2109 Accuracy 0.0035\n",
            "Epoch 5 Step 50 Loss 2332.8752 Accuracy 0.0319\n",
            "Epoch 5 Step 100 Loss 2320.2312 Accuracy 0.0335\n",
            "Epoch 5: Training Loss 2393.4919, Training Accuracy 0.0344\n",
            "Saved checkpoint at epoch 5\n",
            "\n",
            "Start of epoch 6\n",
            "Epoch 6 Step 0 Loss 2227.5732 Accuracy 0.0248\n",
            "Epoch 6 Step 50 Loss 2764.0657 Accuracy 0.0383\n",
            "Epoch 6 Step 100 Loss 2561.7808 Accuracy 0.0377\n",
            "Epoch 6: Training Loss 2529.3245, Training Accuracy 0.0353\n",
            "\n",
            "Start of epoch 7\n",
            "Epoch 7 Step 0 Loss 2345.4951 Accuracy 0.0780\n",
            "Epoch 7 Step 50 Loss 2668.2041 Accuracy 0.0400\n",
            "Epoch 7 Step 100 Loss 2828.6492 Accuracy 0.0380\n",
            "Epoch 7: Training Loss 2774.8850, Training Accuracy 0.0393\n",
            "\n",
            "Start of epoch 8\n",
            "Epoch 8 Step 0 Loss 2839.0349 Accuracy 0.0000\n",
            "Epoch 8 Step 50 Loss 2919.1667 Accuracy 0.0362\n",
            "Epoch 8 Step 100 Loss 2983.2930 Accuracy 0.0375\n",
            "Epoch 8: Training Loss 2856.9902, Training Accuracy 0.0383\n",
            "\n",
            "Start of epoch 9\n",
            "Epoch 9 Step 0 Loss 2496.8589 Accuracy 0.0177\n",
            "Epoch 9 Step 50 Loss 3046.2532 Accuracy 0.0391\n",
            "Epoch 9 Step 100 Loss 3214.6726 Accuracy 0.0406\n",
            "Epoch 9: Training Loss 3195.6504, Training Accuracy 0.0395\n",
            "\n",
            "Start of epoch 10\n",
            "Epoch 10 Step 0 Loss 2715.5715 Accuracy 0.0035\n",
            "Epoch 10 Step 50 Loss 3591.0771 Accuracy 0.0386\n",
            "Epoch 10 Step 100 Loss 3596.6467 Accuracy 0.0387\n",
            "Epoch 10: Training Loss 3554.8333, Training Accuracy 0.0392\n",
            "Saved checkpoint at epoch 10\n",
            "\n",
            "Start of epoch 11\n",
            "Epoch 11 Step 0 Loss 3240.2122 Accuracy 0.0035\n",
            "Epoch 11 Step 50 Loss 3305.3904 Accuracy 0.0416\n",
            "Epoch 11 Step 100 Loss 3500.0935 Accuracy 0.0378\n",
            "Epoch 11: Training Loss 3565.0757, Training Accuracy 0.0375\n",
            "\n",
            "Start of epoch 12\n",
            "Epoch 12 Step 0 Loss 3275.9849 Accuracy 0.0142\n",
            "Epoch 12 Step 50 Loss 3466.5525 Accuracy 0.0439\n",
            "Epoch 12 Step 100 Loss 3656.9243 Accuracy 0.0438\n",
            "Epoch 12: Training Loss 3756.7261, Training Accuracy 0.0421\n",
            "\n",
            "Start of epoch 13\n",
            "Epoch 13 Step 0 Loss 4259.7603 Accuracy 0.0000\n",
            "Epoch 13 Step 50 Loss 3892.6980 Accuracy 0.0415\n",
            "Epoch 13 Step 100 Loss 3593.8171 Accuracy 0.0421\n",
            "Epoch 13: Training Loss 3744.2903, Training Accuracy 0.0412\n",
            "\n",
            "Start of epoch 14\n",
            "Epoch 14 Step 0 Loss 4729.4292 Accuracy 0.0106\n",
            "Epoch 14 Step 50 Loss 4283.9653 Accuracy 0.0415\n",
            "Epoch 14 Step 100 Loss 4228.5283 Accuracy 0.0406\n",
            "Epoch 14: Training Loss 4233.4180, Training Accuracy 0.0422\n",
            "\n",
            "Start of epoch 15\n",
            "Epoch 15 Step 0 Loss 4565.8228 Accuracy 0.0142\n",
            "Epoch 15 Step 50 Loss 3920.0178 Accuracy 0.0415\n",
            "Epoch 15 Step 100 Loss 4089.9031 Accuracy 0.0422\n",
            "Epoch 15: Training Loss 4029.4434, Training Accuracy 0.0413\n",
            "Saved checkpoint at epoch 15\n",
            "\n",
            "Start of epoch 16\n",
            "Epoch 16 Step 0 Loss 4005.7456 Accuracy 0.0213\n",
            "Epoch 16 Step 50 Loss 4570.0376 Accuracy 0.0473\n",
            "Epoch 16 Step 100 Loss 4503.9893 Accuracy 0.0453\n",
            "Epoch 16: Training Loss 4422.7314, Training Accuracy 0.0428\n",
            "\n",
            "Start of epoch 17\n",
            "Epoch 17 Step 0 Loss 5517.5259 Accuracy 0.0000\n",
            "Epoch 17 Step 50 Loss 4584.5830 Accuracy 0.0432\n",
            "Epoch 17 Step 100 Loss 4396.3374 Accuracy 0.0420\n",
            "Epoch 17: Training Loss 4414.7656, Training Accuracy 0.0406\n",
            "\n",
            "Start of epoch 18\n",
            "Epoch 18 Step 0 Loss 5551.1030 Accuracy 0.0319\n",
            "Epoch 18 Step 50 Loss 5071.2881 Accuracy 0.0488\n",
            "Epoch 18 Step 100 Loss 4723.6919 Accuracy 0.0460\n",
            "Epoch 18: Training Loss 4650.8667, Training Accuracy 0.0440\n",
            "\n",
            "Start of epoch 19\n",
            "Epoch 19 Step 0 Loss 5377.6001 Accuracy 0.0000\n",
            "Epoch 19 Step 50 Loss 4687.0977 Accuracy 0.0477\n",
            "Epoch 19 Step 100 Loss 4520.7876 Accuracy 0.0444\n",
            "Epoch 19: Training Loss 4623.4688, Training Accuracy 0.0422\n",
            "\n",
            "Start of epoch 20\n",
            "Epoch 20 Step 0 Loss 4962.0459 Accuracy 0.1738\n",
            "Epoch 20 Step 50 Loss 4818.8867 Accuracy 0.0456\n",
            "Epoch 20 Step 100 Loss 4914.2500 Accuracy 0.0467\n",
            "Epoch 20: Training Loss 4846.8154, Training Accuracy 0.0449\n",
            "Saved checkpoint at epoch 20\n",
            "\n",
            "Start of epoch 21\n",
            "Epoch 21 Step 0 Loss 5294.3091 Accuracy 0.0496\n",
            "Epoch 21 Step 50 Loss 5186.9321 Accuracy 0.0380\n",
            "Epoch 21 Step 100 Loss 5183.3945 Accuracy 0.0427\n",
            "Epoch 21: Training Loss 5122.5664, Training Accuracy 0.0425\n",
            "\n",
            "Start of epoch 22\n",
            "Epoch 22 Step 0 Loss 5319.7026 Accuracy 0.0071\n",
            "Epoch 22 Step 50 Loss 5334.5742 Accuracy 0.0397\n",
            "Epoch 22 Step 100 Loss 5354.8613 Accuracy 0.0403\n",
            "Epoch 22: Training Loss 5324.1177, Training Accuracy 0.0414\n",
            "\n",
            "Start of epoch 23\n",
            "Epoch 23 Step 0 Loss 4637.6392 Accuracy 0.0000\n",
            "Epoch 23 Step 50 Loss 5278.2480 Accuracy 0.0429\n",
            "Epoch 23 Step 100 Loss 5192.8311 Accuracy 0.0428\n",
            "Epoch 23: Training Loss 5122.5605, Training Accuracy 0.0448\n",
            "\n",
            "Start of epoch 24\n",
            "Epoch 24 Step 0 Loss 5947.9946 Accuracy 0.0000\n",
            "Epoch 24 Step 50 Loss 5305.5410 Accuracy 0.0390\n",
            "Epoch 24 Step 100 Loss 5399.7021 Accuracy 0.0408\n",
            "Epoch 24: Training Loss 5363.3438, Training Accuracy 0.0415\n",
            "\n",
            "Start of epoch 25\n",
            "Epoch 25 Step 0 Loss 5705.9053 Accuracy 0.0035\n",
            "Epoch 25 Step 50 Loss 5678.6724 Accuracy 0.0363\n",
            "Epoch 25 Step 100 Loss 5604.9834 Accuracy 0.0434\n",
            "Epoch 25: Training Loss 5562.1372, Training Accuracy 0.0431\n",
            "Saved checkpoint at epoch 25\n",
            "\n",
            "Start of epoch 26\n",
            "Epoch 26 Step 0 Loss 6260.6460 Accuracy 0.0000\n",
            "Epoch 26 Step 50 Loss 6218.7930 Accuracy 0.0408\n",
            "Epoch 26 Step 100 Loss 5928.5459 Accuracy 0.0397\n",
            "Epoch 26: Training Loss 5903.1553, Training Accuracy 0.0410\n",
            "\n",
            "Start of epoch 27\n",
            "Epoch 27 Step 0 Loss 6493.9077 Accuracy 0.0071\n",
            "Epoch 27 Step 50 Loss 5567.9312 Accuracy 0.0386\n",
            "Epoch 27 Step 100 Loss 5666.9722 Accuracy 0.0422\n",
            "Epoch 27: Training Loss 5586.4658, Training Accuracy 0.0434\n",
            "\n",
            "Start of epoch 28\n",
            "Epoch 28 Step 0 Loss 7263.0073 Accuracy 0.0071\n",
            "Epoch 28 Step 50 Loss 5473.8750 Accuracy 0.0430\n",
            "Epoch 28 Step 100 Loss 5593.7476 Accuracy 0.0440\n",
            "Epoch 28: Training Loss 5662.0952, Training Accuracy 0.0426\n",
            "\n",
            "Start of epoch 29\n",
            "Epoch 29 Step 0 Loss 5753.7852 Accuracy 0.0071\n",
            "Epoch 29 Step 50 Loss 5931.6182 Accuracy 0.0468\n",
            "Epoch 29 Step 100 Loss 5573.5156 Accuracy 0.0452\n",
            "Epoch 29: Training Loss 5622.3828, Training Accuracy 0.0450\n",
            "\n",
            "Start of epoch 30\n",
            "Epoch 30 Step 0 Loss 5481.4321 Accuracy 0.0248\n",
            "Epoch 30 Step 50 Loss 6075.2290 Accuracy 0.0473\n",
            "Epoch 30 Step 100 Loss 6233.1621 Accuracy 0.0453\n",
            "Epoch 30: Training Loss 5992.1074, Training Accuracy 0.0436\n",
            "Saved checkpoint at epoch 30\n",
            "\n",
            "Start of epoch 31\n",
            "Epoch 31 Step 0 Loss 6342.5552 Accuracy 0.0000\n",
            "Epoch 31 Step 50 Loss 6502.9160 Accuracy 0.0456\n",
            "Epoch 31 Step 100 Loss 6617.4971 Accuracy 0.0440\n",
            "Epoch 31: Training Loss 6469.7500, Training Accuracy 0.0456\n",
            "\n",
            "Start of epoch 32\n",
            "Epoch 32 Step 0 Loss 5404.0513 Accuracy 0.0000\n",
            "Epoch 32 Step 50 Loss 5993.4600 Accuracy 0.0393\n",
            "Epoch 32 Step 100 Loss 6378.5181 Accuracy 0.0430\n",
            "Epoch 32: Training Loss 6353.7437, Training Accuracy 0.0419\n",
            "\n",
            "Start of epoch 33\n",
            "Epoch 33 Step 0 Loss 7650.5938 Accuracy 0.0213\n",
            "Epoch 33 Step 50 Loss 6976.3896 Accuracy 0.0448\n",
            "Epoch 33 Step 100 Loss 6833.1040 Accuracy 0.0439\n",
            "Epoch 33: Training Loss 6645.8188, Training Accuracy 0.0445\n",
            "\n",
            "Start of epoch 34\n",
            "Epoch 34 Step 0 Loss 6446.8618 Accuracy 0.0000\n",
            "Epoch 34 Step 50 Loss 6821.4087 Accuracy 0.0426\n",
            "Epoch 34 Step 100 Loss 6620.8105 Accuracy 0.0431\n",
            "Epoch 34: Training Loss 6500.7402, Training Accuracy 0.0435\n",
            "\n",
            "Start of epoch 35\n",
            "Epoch 35 Step 0 Loss 6335.2227 Accuracy 0.0000\n",
            "Epoch 35 Step 50 Loss 6774.5215 Accuracy 0.0445\n",
            "Epoch 35 Step 100 Loss 6685.1533 Accuracy 0.0446\n",
            "Epoch 35: Training Loss 6712.7144, Training Accuracy 0.0448\n",
            "Saved checkpoint at epoch 35\n",
            "\n",
            "Start of epoch 36\n",
            "Epoch 36 Step 0 Loss 4868.1919 Accuracy 0.0106\n",
            "Epoch 36 Step 50 Loss 6767.4668 Accuracy 0.0434\n",
            "Epoch 36 Step 100 Loss 6622.2129 Accuracy 0.0451\n",
            "Epoch 36: Training Loss 6467.0264, Training Accuracy 0.0439\n",
            "\n",
            "Start of epoch 37\n",
            "Epoch 37 Step 0 Loss 6353.9468 Accuracy 0.0000\n",
            "Epoch 37 Step 50 Loss 6471.3940 Accuracy 0.0406\n",
            "Epoch 37 Step 100 Loss 6729.6602 Accuracy 0.0419\n",
            "Epoch 37: Training Loss 6729.5166, Training Accuracy 0.0436\n",
            "\n",
            "Start of epoch 38\n",
            "Epoch 38 Step 0 Loss 6993.1582 Accuracy 0.0106\n",
            "Epoch 38 Step 50 Loss 7308.0063 Accuracy 0.0400\n",
            "Epoch 38 Step 100 Loss 7263.4883 Accuracy 0.0429\n",
            "Epoch 38: Training Loss 7118.3638, Training Accuracy 0.0434\n",
            "\n",
            "Start of epoch 39\n",
            "Epoch 39 Step 0 Loss 6583.3628 Accuracy 0.0000\n",
            "Epoch 39 Step 50 Loss 6708.6875 Accuracy 0.0414\n",
            "Epoch 39 Step 100 Loss 6940.7686 Accuracy 0.0437\n",
            "Epoch 39: Training Loss 6755.5391, Training Accuracy 0.0447\n",
            "\n",
            "Start of epoch 40\n",
            "Epoch 40 Step 0 Loss 6573.7168 Accuracy 0.0000\n",
            "Epoch 40 Step 50 Loss 7246.0801 Accuracy 0.0451\n",
            "Epoch 40 Step 100 Loss 6932.4531 Accuracy 0.0464\n",
            "Epoch 40: Training Loss 7045.8823, Training Accuracy 0.0460\n",
            "Saved checkpoint at epoch 40\n",
            "\n",
            "Start of epoch 41\n",
            "Epoch 41 Step 0 Loss 7323.9927 Accuracy 0.0000\n",
            "Epoch 41 Step 50 Loss 6874.6001 Accuracy 0.0418\n",
            "Epoch 41 Step 100 Loss 7101.3701 Accuracy 0.0425\n",
            "Epoch 41: Training Loss 7008.8452, Training Accuracy 0.0436\n",
            "\n",
            "Start of epoch 42\n",
            "Epoch 42 Step 0 Loss 7703.9556 Accuracy 0.0000\n",
            "Epoch 42 Step 50 Loss 6977.9985 Accuracy 0.0473\n",
            "Epoch 42 Step 100 Loss 7018.0952 Accuracy 0.0446\n",
            "Epoch 42: Training Loss 6999.8218, Training Accuracy 0.0454\n",
            "\n",
            "Start of epoch 43\n",
            "Epoch 43 Step 0 Loss 6736.4160 Accuracy 0.1631\n",
            "Epoch 43 Step 50 Loss 6983.3984 Accuracy 0.0409\n",
            "Epoch 43 Step 100 Loss 7132.1196 Accuracy 0.0418\n",
            "Epoch 43: Training Loss 7396.3154, Training Accuracy 0.0407\n",
            "\n",
            "Start of epoch 44\n",
            "Epoch 44 Step 0 Loss 7907.9966 Accuracy 0.2092\n",
            "Epoch 44 Step 50 Loss 8260.2988 Accuracy 0.0430\n",
            "Epoch 44 Step 100 Loss 7931.2192 Accuracy 0.0467\n",
            "Epoch 44: Training Loss 7605.5894, Training Accuracy 0.0446\n",
            "\n",
            "Start of epoch 45\n",
            "Epoch 45 Step 0 Loss 6257.4214 Accuracy 0.0284\n",
            "Epoch 45 Step 50 Loss 7659.1040 Accuracy 0.0459\n",
            "Epoch 45 Step 100 Loss 7543.5508 Accuracy 0.0405\n",
            "Epoch 45: Training Loss 7567.4683, Training Accuracy 0.0426\n",
            "Saved checkpoint at epoch 45\n",
            "\n",
            "Start of epoch 46\n",
            "Epoch 46 Step 0 Loss 8058.1958 Accuracy 0.0035\n",
            "Epoch 46 Step 50 Loss 8270.2363 Accuracy 0.0389\n",
            "Epoch 46 Step 100 Loss 8526.3887 Accuracy 0.0421\n",
            "Epoch 46: Training Loss 8201.6553, Training Accuracy 0.0446\n",
            "\n",
            "Start of epoch 47\n",
            "Epoch 47 Step 0 Loss 5998.3604 Accuracy 0.1241\n",
            "Epoch 47 Step 50 Loss 7689.4585 Accuracy 0.0480\n",
            "Epoch 47 Step 100 Loss 8038.6904 Accuracy 0.0455\n",
            "Epoch 47: Training Loss 7807.9292, Training Accuracy 0.0443\n",
            "\n",
            "Start of epoch 48\n",
            "Epoch 48 Step 0 Loss 6409.1011 Accuracy 0.0035\n",
            "Epoch 48 Step 50 Loss 7551.5220 Accuracy 0.0421\n",
            "Epoch 48 Step 100 Loss 7899.3140 Accuracy 0.0411\n",
            "Epoch 48: Training Loss 7873.2280, Training Accuracy 0.0441\n",
            "\n",
            "Start of epoch 49\n",
            "Epoch 49 Step 0 Loss 6735.7642 Accuracy 0.0000\n",
            "Epoch 49 Step 50 Loss 7943.5103 Accuracy 0.0455\n",
            "Epoch 49 Step 100 Loss 7965.7808 Accuracy 0.0445\n",
            "Epoch 49: Training Loss 7815.8423, Training Accuracy 0.0424\n",
            "\n",
            "Start of epoch 50\n",
            "Epoch 50 Step 0 Loss 7769.6914 Accuracy 0.0284\n",
            "Epoch 50 Step 50 Loss 8020.0176 Accuracy 0.0480\n",
            "Epoch 50 Step 100 Loss 7792.5005 Accuracy 0.0431\n",
            "Epoch 50: Training Loss 7623.3784, Training Accuracy 0.0437\n",
            "Saved checkpoint at epoch 50\n",
            "\n",
            "Start of epoch 51\n",
            "Epoch 51 Step 0 Loss 7810.4849 Accuracy 0.0922\n",
            "Epoch 51 Step 50 Loss 7952.6304 Accuracy 0.0410\n",
            "Epoch 51 Step 100 Loss 8232.8652 Accuracy 0.0447\n",
            "Epoch 51: Training Loss 8080.0913, Training Accuracy 0.0436\n",
            "\n",
            "Start of epoch 52\n",
            "Epoch 52 Step 0 Loss 6915.2456 Accuracy 0.0674\n",
            "Epoch 52 Step 50 Loss 8274.7158 Accuracy 0.0462\n",
            "Epoch 52 Step 100 Loss 8465.7461 Accuracy 0.0457\n",
            "Epoch 52: Training Loss 8376.0381, Training Accuracy 0.0471\n",
            "\n",
            "Start of epoch 53\n",
            "Epoch 53 Step 0 Loss 9637.5850 Accuracy 0.0035\n",
            "Epoch 53 Step 50 Loss 8154.4043 Accuracy 0.0412\n",
            "Epoch 53 Step 100 Loss 7972.0518 Accuracy 0.0436\n",
            "Epoch 53: Training Loss 7899.0122, Training Accuracy 0.0423\n",
            "\n",
            "Start of epoch 54\n",
            "Epoch 54 Step 0 Loss 8715.4854 Accuracy 0.0426\n",
            "Epoch 54 Step 50 Loss 8659.9004 Accuracy 0.0482\n",
            "Epoch 54 Step 100 Loss 8713.1699 Accuracy 0.0463\n",
            "Epoch 54: Training Loss 8599.9795, Training Accuracy 0.0454\n",
            "\n",
            "Start of epoch 55\n",
            "Epoch 55 Step 0 Loss 8129.2622 Accuracy 0.2234\n",
            "Epoch 55 Step 50 Loss 8653.8662 Accuracy 0.0463\n",
            "Epoch 55 Step 100 Loss 9083.0342 Accuracy 0.0442\n",
            "Epoch 55: Training Loss 9125.5967, Training Accuracy 0.0451\n",
            "Saved checkpoint at epoch 55\n",
            "\n",
            "Start of epoch 56\n",
            "Epoch 56 Step 0 Loss 7658.1987 Accuracy 0.0426\n",
            "Epoch 56 Step 50 Loss 8053.6387 Accuracy 0.0402\n",
            "Epoch 56 Step 100 Loss 8570.2314 Accuracy 0.0446\n",
            "Epoch 56: Training Loss 8505.0547, Training Accuracy 0.0443\n",
            "\n",
            "Start of epoch 57\n",
            "Epoch 57 Step 0 Loss 8742.9141 Accuracy 0.0142\n",
            "Epoch 57 Step 50 Loss 8867.5664 Accuracy 0.0362\n",
            "Epoch 57 Step 100 Loss 8656.4668 Accuracy 0.0411\n",
            "Epoch 57: Training Loss 8481.6211, Training Accuracy 0.0412\n",
            "\n",
            "Start of epoch 58\n",
            "Epoch 58 Step 0 Loss 9006.0068 Accuracy 0.1950\n",
            "Epoch 58 Step 50 Loss 8656.6309 Accuracy 0.0454\n",
            "Epoch 58 Step 100 Loss 8796.1104 Accuracy 0.0461\n",
            "Epoch 58: Training Loss 8839.0703, Training Accuracy 0.0446\n",
            "\n",
            "Start of epoch 59\n",
            "Epoch 59 Step 0 Loss 9289.2627 Accuracy 0.0319\n",
            "Epoch 59 Step 50 Loss 9094.0322 Accuracy 0.0443\n",
            "Epoch 59 Step 100 Loss 9134.7441 Accuracy 0.0436\n",
            "Epoch 59: Training Loss 9321.2012, Training Accuracy 0.0456\n",
            "\n",
            "Start of epoch 60\n",
            "Epoch 60 Step 0 Loss 9472.1992 Accuracy 0.0355\n",
            "Epoch 60 Step 50 Loss 9444.8047 Accuracy 0.0404\n",
            "Epoch 60 Step 100 Loss 8985.0059 Accuracy 0.0470\n",
            "Epoch 60: Training Loss 8990.0068, Training Accuracy 0.0442\n",
            "Saved checkpoint at epoch 60\n",
            "\n",
            "Start of epoch 61\n",
            "Epoch 61 Step 0 Loss 8696.7959 Accuracy 0.0071\n",
            "Epoch 61 Step 50 Loss 10266.5469 Accuracy 0.0411\n",
            "Epoch 61 Step 100 Loss 10035.4521 Accuracy 0.0444\n",
            "Epoch 61: Training Loss 9579.9980, Training Accuracy 0.0426\n",
            "\n",
            "Start of epoch 62\n",
            "Epoch 62 Step 0 Loss 9926.8750 Accuracy 0.0000\n",
            "Epoch 62 Step 50 Loss 9254.3096 Accuracy 0.0498\n",
            "Epoch 62 Step 100 Loss 9308.2139 Accuracy 0.0477\n",
            "Epoch 62: Training Loss 9398.7129, Training Accuracy 0.0478\n",
            "\n",
            "Start of epoch 63\n",
            "Epoch 63 Step 0 Loss 8147.6880 Accuracy 0.0071\n",
            "Epoch 63 Step 50 Loss 9718.0723 Accuracy 0.0443\n",
            "Epoch 63 Step 100 Loss 9369.9922 Accuracy 0.0438\n",
            "Epoch 63: Training Loss 9408.6289, Training Accuracy 0.0451\n",
            "\n",
            "Start of epoch 64\n",
            "Epoch 64 Step 0 Loss 8738.3320 Accuracy 0.0248\n",
            "Epoch 64 Step 50 Loss 9138.8096 Accuracy 0.0417\n",
            "Epoch 64 Step 100 Loss 9467.8652 Accuracy 0.0428\n",
            "Epoch 64: Training Loss 9486.9131, Training Accuracy 0.0432\n",
            "\n",
            "Start of epoch 65\n",
            "Epoch 65 Step 0 Loss 9298.1914 Accuracy 0.0000\n",
            "Epoch 65 Step 50 Loss 8718.5195 Accuracy 0.0472\n",
            "Epoch 65 Step 100 Loss 8915.6484 Accuracy 0.0416\n",
            "Epoch 65: Training Loss 8943.4180, Training Accuracy 0.0402\n",
            "Saved checkpoint at epoch 65\n",
            "\n",
            "Start of epoch 66\n",
            "Epoch 66 Step 0 Loss 9618.5605 Accuracy 0.0284\n",
            "Epoch 66 Step 50 Loss 10103.4863 Accuracy 0.0482\n",
            "Epoch 66 Step 100 Loss 10093.2627 Accuracy 0.0461\n",
            "Epoch 66: Training Loss 9974.6035, Training Accuracy 0.0457\n",
            "\n",
            "Start of epoch 67\n",
            "Epoch 67 Step 0 Loss 10119.4932 Accuracy 0.0142\n",
            "Epoch 67 Step 50 Loss 9833.2188 Accuracy 0.0430\n",
            "Epoch 67 Step 100 Loss 9700.7588 Accuracy 0.0445\n",
            "Epoch 67: Training Loss 9718.0947, Training Accuracy 0.0458\n",
            "\n",
            "Start of epoch 68\n",
            "Epoch 68 Step 0 Loss 8691.6162 Accuracy 0.0000\n",
            "Epoch 68 Step 50 Loss 9415.3662 Accuracy 0.0477\n",
            "Epoch 68 Step 100 Loss 9441.3379 Accuracy 0.0434\n",
            "Epoch 68: Training Loss 9257.8887, Training Accuracy 0.0437\n",
            "\n",
            "Start of epoch 69\n",
            "Epoch 69 Step 0 Loss 11053.8916 Accuracy 0.0071\n",
            "Epoch 69 Step 50 Loss 10743.6113 Accuracy 0.0423\n",
            "Epoch 69 Step 100 Loss 10825.9395 Accuracy 0.0455\n",
            "Epoch 69: Training Loss 10577.0244, Training Accuracy 0.0464\n",
            "\n",
            "Start of epoch 70\n",
            "Epoch 70 Step 0 Loss 9211.2686 Accuracy 0.0000\n",
            "Epoch 70 Step 50 Loss 9866.4014 Accuracy 0.0382\n",
            "Epoch 70 Step 100 Loss 10092.5781 Accuracy 0.0447\n",
            "Epoch 70: Training Loss 9875.0361, Training Accuracy 0.0431\n",
            "Saved checkpoint at epoch 70\n",
            "\n",
            "Start of epoch 71\n",
            "Epoch 71 Step 0 Loss 9531.4365 Accuracy 0.0284\n",
            "Epoch 71 Step 50 Loss 9789.6992 Accuracy 0.0462\n",
            "Epoch 71 Step 100 Loss 9869.9023 Accuracy 0.0456\n",
            "Epoch 71: Training Loss 9921.7744, Training Accuracy 0.0430\n",
            "\n",
            "Start of epoch 72\n",
            "Epoch 72 Step 0 Loss 10033.2549 Accuracy 0.0745\n",
            "Epoch 72 Step 50 Loss 10037.0518 Accuracy 0.0449\n",
            "Epoch 72 Step 100 Loss 9849.1904 Accuracy 0.0470\n",
            "Epoch 72: Training Loss 9957.7637, Training Accuracy 0.0457\n",
            "\n",
            "Start of epoch 73\n",
            "Epoch 73 Step 0 Loss 8599.6006 Accuracy 0.0000\n",
            "Epoch 73 Step 50 Loss 10122.0303 Accuracy 0.0439\n",
            "Epoch 73 Step 100 Loss 10616.5225 Accuracy 0.0438\n",
            "Epoch 73: Training Loss 10438.6475, Training Accuracy 0.0444\n",
            "\n",
            "Start of epoch 74\n",
            "Epoch 74 Step 0 Loss 8562.4414 Accuracy 0.1950\n",
            "Epoch 74 Step 50 Loss 9629.7871 Accuracy 0.0507\n",
            "Epoch 74 Step 100 Loss 10016.5918 Accuracy 0.0496\n",
            "Epoch 74: Training Loss 10012.4727, Training Accuracy 0.0480\n",
            "\n",
            "Start of epoch 75\n",
            "Epoch 75 Step 0 Loss 9093.2568 Accuracy 0.0284\n",
            "Epoch 75 Step 50 Loss 9984.5977 Accuracy 0.0435\n",
            "Epoch 75 Step 100 Loss 10156.1514 Accuracy 0.0432\n",
            "Epoch 75: Training Loss 10151.6348, Training Accuracy 0.0430\n",
            "Saved checkpoint at epoch 75\n",
            "\n",
            "Start of epoch 76\n",
            "Epoch 76 Step 0 Loss 9862.4014 Accuracy 0.0000\n",
            "Epoch 76 Step 50 Loss 11727.4775 Accuracy 0.0431\n",
            "Epoch 76 Step 100 Loss 11872.2510 Accuracy 0.0400\n",
            "Epoch 76: Training Loss 11410.5498, Training Accuracy 0.0423\n",
            "\n",
            "Start of epoch 77\n",
            "Epoch 77 Step 0 Loss 10132.3057 Accuracy 0.0000\n",
            "Epoch 77 Step 50 Loss 10279.9873 Accuracy 0.0440\n",
            "Epoch 77 Step 100 Loss 11116.3809 Accuracy 0.0438\n",
            "Epoch 77: Training Loss 11064.1484, Training Accuracy 0.0433\n",
            "\n",
            "Start of epoch 78\n",
            "Epoch 78 Step 0 Loss 10325.8613 Accuracy 0.0035\n",
            "Epoch 78 Step 50 Loss 10407.7949 Accuracy 0.0397\n",
            "Epoch 78 Step 100 Loss 10537.3721 Accuracy 0.0428\n",
            "Epoch 78: Training Loss 10312.0820, Training Accuracy 0.0412\n",
            "\n",
            "Start of epoch 79\n",
            "Epoch 79 Step 0 Loss 10222.9482 Accuracy 0.0035\n",
            "Epoch 79 Step 50 Loss 10228.8496 Accuracy 0.0415\n",
            "Epoch 79 Step 100 Loss 10632.0967 Accuracy 0.0419\n",
            "Epoch 79: Training Loss 10723.2090, Training Accuracy 0.0409\n",
            "\n",
            "Start of epoch 80\n",
            "Epoch 80 Step 0 Loss 7492.3760 Accuracy 0.0035\n",
            "Epoch 80 Step 50 Loss 11139.7148 Accuracy 0.0437\n",
            "Epoch 80 Step 100 Loss 11166.8828 Accuracy 0.0435\n",
            "Epoch 80: Training Loss 11218.2520, Training Accuracy 0.0449\n",
            "Saved checkpoint at epoch 80\n",
            "\n",
            "Start of epoch 81\n",
            "Epoch 81 Step 0 Loss 10264.2168 Accuracy 0.1667\n",
            "Epoch 81 Step 50 Loss 10844.1162 Accuracy 0.0435\n",
            "Epoch 81 Step 100 Loss 10756.0723 Accuracy 0.0454\n",
            "Epoch 81: Training Loss 10907.8799, Training Accuracy 0.0448\n",
            "\n",
            "Start of epoch 82\n",
            "Epoch 82 Step 0 Loss 9711.9277 Accuracy 0.0674\n",
            "Epoch 82 Step 50 Loss 10527.4707 Accuracy 0.0462\n",
            "Epoch 82 Step 100 Loss 10972.2871 Accuracy 0.0465\n",
            "Epoch 82: Training Loss 11066.1816, Training Accuracy 0.0448\n",
            "\n",
            "Start of epoch 83\n",
            "Epoch 83 Step 0 Loss 12330.6025 Accuracy 0.0000\n",
            "Epoch 83 Step 50 Loss 11676.6738 Accuracy 0.0404\n",
            "Epoch 83 Step 100 Loss 11629.9268 Accuracy 0.0403\n",
            "Epoch 83: Training Loss 11414.3008, Training Accuracy 0.0408\n",
            "\n",
            "Start of epoch 84\n",
            "Epoch 84 Step 0 Loss 12053.4434 Accuracy 0.0000\n",
            "Epoch 84 Step 50 Loss 11544.2686 Accuracy 0.0462\n",
            "Epoch 84 Step 100 Loss 10957.9482 Accuracy 0.0463\n",
            "Epoch 84: Training Loss 10730.7422, Training Accuracy 0.0470\n",
            "\n",
            "Start of epoch 85\n",
            "Epoch 85 Step 0 Loss 11832.9502 Accuracy 0.0035\n",
            "Epoch 85 Step 50 Loss 11101.8037 Accuracy 0.0408\n",
            "Epoch 85 Step 100 Loss 11604.6953 Accuracy 0.0428\n",
            "Epoch 85: Training Loss 11623.4531, Training Accuracy 0.0433\n",
            "Saved checkpoint at epoch 85\n",
            "\n",
            "Start of epoch 86\n",
            "Epoch 86 Step 0 Loss 11050.7480 Accuracy 0.0355\n",
            "Epoch 86 Step 50 Loss 11379.2529 Accuracy 0.0395\n",
            "Epoch 86 Step 100 Loss 11532.8779 Accuracy 0.0419\n",
            "Epoch 86: Training Loss 11274.0137, Training Accuracy 0.0432\n",
            "\n",
            "Start of epoch 87\n",
            "Epoch 87 Step 0 Loss 10317.2773 Accuracy 0.1879\n",
            "Epoch 87 Step 50 Loss 12170.7119 Accuracy 0.0429\n",
            "Epoch 87 Step 100 Loss 12187.2324 Accuracy 0.0425\n",
            "Epoch 87: Training Loss 11927.0273, Training Accuracy 0.0441\n",
            "\n",
            "Start of epoch 88\n",
            "Epoch 88 Step 0 Loss 9224.9170 Accuracy 0.0248\n",
            "Epoch 88 Step 50 Loss 11507.9551 Accuracy 0.0417\n",
            "Epoch 88 Step 100 Loss 11365.4531 Accuracy 0.0432\n",
            "Epoch 88: Training Loss 11451.3018, Training Accuracy 0.0461\n",
            "\n",
            "Start of epoch 89\n",
            "Epoch 89 Step 0 Loss 11750.5625 Accuracy 0.0000\n",
            "Epoch 89 Step 50 Loss 11019.2510 Accuracy 0.0406\n",
            "Epoch 89 Step 100 Loss 11286.1123 Accuracy 0.0432\n",
            "Epoch 89: Training Loss 11529.6699, Training Accuracy 0.0414\n",
            "\n",
            "Start of epoch 90\n",
            "Epoch 90 Step 0 Loss 12131.0596 Accuracy 0.0035\n",
            "Epoch 90 Step 50 Loss 11623.2197 Accuracy 0.0387\n",
            "Epoch 90 Step 100 Loss 11577.9717 Accuracy 0.0418\n",
            "Epoch 90: Training Loss 11258.5547, Training Accuracy 0.0421\n",
            "Saved checkpoint at epoch 90\n",
            "\n",
            "Start of epoch 91\n",
            "Epoch 91 Step 0 Loss 10307.7412 Accuracy 0.0355\n",
            "Epoch 91 Step 50 Loss 11117.2686 Accuracy 0.0471\n",
            "Epoch 91 Step 100 Loss 11349.3477 Accuracy 0.0454\n",
            "Epoch 91: Training Loss 11403.4609, Training Accuracy 0.0440\n",
            "\n",
            "Start of epoch 92\n",
            "Epoch 92 Step 0 Loss 11546.8877 Accuracy 0.0035\n",
            "Epoch 92 Step 50 Loss 12147.0732 Accuracy 0.0448\n",
            "Epoch 92 Step 100 Loss 12070.6943 Accuracy 0.0449\n",
            "Epoch 92: Training Loss 11963.9746, Training Accuracy 0.0449\n",
            "\n",
            "Start of epoch 93\n",
            "Epoch 93 Step 0 Loss 11095.1943 Accuracy 0.0035\n",
            "Epoch 93 Step 50 Loss 12593.6504 Accuracy 0.0391\n",
            "Epoch 93 Step 100 Loss 12575.9844 Accuracy 0.0410\n",
            "Epoch 93: Training Loss 12433.8877, Training Accuracy 0.0428\n",
            "\n",
            "Start of epoch 94\n",
            "Epoch 94 Step 0 Loss 10319.9834 Accuracy 0.0000\n",
            "Epoch 94 Step 50 Loss 11969.7734 Accuracy 0.0378\n",
            "Epoch 94 Step 100 Loss 12614.8838 Accuracy 0.0376\n",
            "Epoch 94: Training Loss 12661.4375, Training Accuracy 0.0413\n",
            "\n",
            "Start of epoch 95\n",
            "Epoch 95 Step 0 Loss 10343.3799 Accuracy 0.1560\n",
            "Epoch 95 Step 50 Loss 11997.2441 Accuracy 0.0484\n",
            "Epoch 95 Step 100 Loss 12358.6670 Accuracy 0.0463\n",
            "Epoch 95: Training Loss 12224.5898, Training Accuracy 0.0460\n",
            "Saved checkpoint at epoch 95\n",
            "\n",
            "Start of epoch 96\n",
            "Epoch 96 Step 0 Loss 11698.3633 Accuracy 0.0000\n",
            "Epoch 96 Step 50 Loss 11718.4990 Accuracy 0.0484\n",
            "Epoch 96 Step 100 Loss 11733.7402 Accuracy 0.0430\n",
            "Epoch 96: Training Loss 12330.5547, Training Accuracy 0.0437\n",
            "\n",
            "Start of epoch 97\n",
            "Epoch 97 Step 0 Loss 13585.7432 Accuracy 0.0000\n",
            "Epoch 97 Step 50 Loss 13441.7695 Accuracy 0.0421\n",
            "Epoch 97 Step 100 Loss 12720.8887 Accuracy 0.0401\n",
            "Epoch 97: Training Loss 12707.7734, Training Accuracy 0.0419\n",
            "\n",
            "Start of epoch 98\n",
            "Epoch 98 Step 0 Loss 11714.2676 Accuracy 0.0071\n",
            "Epoch 98 Step 50 Loss 13140.5713 Accuracy 0.0412\n",
            "Epoch 98 Step 100 Loss 12483.7100 Accuracy 0.0441\n",
            "Epoch 98: Training Loss 12638.6279, Training Accuracy 0.0445\n",
            "\n",
            "Start of epoch 99\n",
            "Epoch 99 Step 0 Loss 11634.6582 Accuracy 0.0248\n",
            "Epoch 99 Step 50 Loss 13015.4678 Accuracy 0.0390\n",
            "Epoch 99 Step 100 Loss 12811.3994 Accuracy 0.0397\n",
            "Epoch 99: Training Loss 12665.6055, Training Accuracy 0.0414\n",
            "\n",
            "Start of epoch 100\n",
            "Epoch 100 Step 0 Loss 10874.2539 Accuracy 0.0709\n",
            "Epoch 100 Step 50 Loss 12685.3994 Accuracy 0.0409\n",
            "Epoch 100 Step 100 Loss 12472.4629 Accuracy 0.0404\n",
            "Epoch 100: Training Loss 12356.8701, Training Accuracy 0.0410\n",
            "Saved checkpoint at epoch 100\n",
            "\n",
            "Total time taken: 8.28s\n"
          ]
        }
      ],
      "source": [
        "# https://machinelearningmastery.com/training-the-transformer-model/\n",
        "# https://machinelearningmastery.com/joining-the-transformer-encoder-and-decoder-and-masking/\n",
        "\n",
        "# MY REPOSITORY\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# TOOLS Locations:\n",
        "basepath='/content/drive/MyDrive/tools'\n",
        "#/content/drive/MyDrive/tools/utils.py\n",
        "%cd /content/drive/MyDrive/tools/\n",
        "from utils import TransformerModel,PrepareDataset\n",
        "%cd /content/\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers.schedules import LearningRateSchedule\n",
        "from tensorflow.keras.metrics import Mean\n",
        "from tensorflow import data, train, math, reduce_sum, cast, equal, argmax, float32, GradientTape, TensorSpec, function, int64\n",
        "from keras.losses import sparse_categorical_crossentropy\n",
        "\n",
        "#original in the code\n",
        "#from model import TransformerModel\n",
        "#from prepare_dataset import PrepareDataset\n",
        "\n",
        "from time import time\n",
        "\n",
        "# Define the model parameters\n",
        "h = 8  # Number of self-attention heads\n",
        "d_k = 64  # Dimensionality of the linearly projected queries and keys\n",
        "d_v = 64  # Dimensionality of the linearly projected values\n",
        "d_model = 512  # Dimensionality of model layers' outputs\n",
        "d_ff = 2048  # Dimensionality of the inner fully connected layer\n",
        "n = 6  # Number of layers in the encoder stack\n",
        "\n",
        "# Define the training parameters\n",
        "epochs = 100\n",
        "batch_size = 64\n",
        "beta_1 = 0.9\n",
        "beta_2 = 0.98\n",
        "epsilon = 1e-9\n",
        "dropout_rate = 0.1\n",
        "\n",
        "\n",
        "# Implementing a learning rate scheduler\n",
        "class LRScheduler(LearningRateSchedule):\n",
        "    def __init__(self, d_model, warmup_steps=4000, **kwargs):\n",
        "        super(LRScheduler, self).__init__(**kwargs)\n",
        "\n",
        "        self.d_model = cast(d_model, int64)\n",
        "        self.warmup_steps = warmup_steps\n",
        "\n",
        "    def __call__(self, step_num):\n",
        "\n",
        "        # Linearly increasing the learning rate for the first warmup_steps, and decreasing it thereafter\n",
        "        arg1 = step_num ** int(-0.5)\n",
        "        arg2 = step_num * (self.warmup_steps ** int(1.5))\n",
        "\n",
        "        return (self.d_model ** int(-0.5)) * math.minimum(arg1, arg2)\n",
        "\n",
        "\n",
        "# Instantiate an Adam optimizer\n",
        "optimizer = Adam(LRScheduler(d_model), beta_1, beta_2, epsilon)\n",
        "\n",
        "# Prepare the training and test splits of the dataset\n",
        "dataset = PrepareDataset()\n",
        "trainX, trainY, train_orig, enc_seq_length, dec_seq_length, enc_vocab_size, dec_vocab_size = dataset('/content/drive/MyDrive/tools/english-german-both.pkl')\n",
        "\n",
        "# Prepare the dataset batches\n",
        "train_dataset = data.Dataset.from_tensor_slices((trainX, trainY))\n",
        "train_dataset = train_dataset.batch(batch_size)\n",
        "\n",
        "# Create model\n",
        "training_model = TransformerModel(enc_vocab_size, dec_vocab_size, enc_seq_length, dec_seq_length, h, d_k, d_v, d_model, d_ff, n, dropout_rate)\n",
        "\n",
        "\n",
        "# Defining the loss function\n",
        "def loss_fcn(target, prediction):\n",
        "    # Create mask so that the zero padding values are not included in the computation of loss\n",
        "    padding_mask = math.logical_not(equal(target, 0))\n",
        "    padding_mask = cast(padding_mask, float32)\n",
        "\n",
        "    # Compute a sparse categorical cross-entropy loss on the unmasked values\n",
        "    loss = sparse_categorical_crossentropy(target, prediction, from_logits=True) * padding_mask\n",
        "\n",
        "    # Compute the mean loss over the unmasked values\n",
        "    return reduce_sum(loss) / reduce_sum(padding_mask)\n",
        "\n",
        "\n",
        "# Defining the accuracy function\n",
        "def accuracy_fcn(target, prediction):\n",
        "    # Create mask so that the zero padding values are not included in the computation of accuracy\n",
        "    padding_mask = math.logical_not(equal(target, 0))\n",
        "\n",
        "    # Find equal prediction and target values, and apply the padding mask\n",
        "    accuracy = equal(target, argmax(prediction, axis=2))\n",
        "    accuracy = math.logical_and(padding_mask, accuracy)\n",
        "\n",
        "    # Cast the True/False values to 32-bit-precision floating-point numbers\n",
        "    padding_mask = cast(padding_mask, float32)\n",
        "    accuracy = cast(accuracy, float32)\n",
        "\n",
        "    # Compute the mean accuracy over the unmasked values\n",
        "    return reduce_sum(accuracy) / reduce_sum(padding_mask)\n",
        "\n",
        "\n",
        "# Include metrics monitoring\n",
        "train_loss = Mean(name='train_loss')\n",
        "train_accuracy = Mean(name='train_accuracy')\n",
        "\n",
        "# Create a checkpoint object and manager to manage multiple checkpoints\n",
        "ckpt = train.Checkpoint(model=training_model, optimizer=optimizer)\n",
        "ckpt_manager = train.CheckpointManager(ckpt, \"./checkpoints\", max_to_keep=3)\n",
        "\n",
        "# Speeding up the training process\n",
        "@function\n",
        "def train_step(encoder_input, decoder_input, decoder_output):\n",
        "    with GradientTape() as tape:\n",
        "\n",
        "        # Run the forward pass of the model to generate a prediction\n",
        "        prediction = training_model(encoder_input, decoder_input, training=True)\n",
        "\n",
        "        # Compute the training loss\n",
        "        loss = loss_fcn(decoder_output, prediction)\n",
        "\n",
        "        # Compute the training accuracy\n",
        "        accuracy = accuracy_fcn(decoder_output, prediction)\n",
        "\n",
        "    # Retrieve gradients of the trainable variables with respect to the training loss\n",
        "    gradients = tape.gradient(loss, training_model.trainable_weights)\n",
        "\n",
        "    # Update the values of the trainable variables by gradient descent\n",
        "    optimizer.apply_gradients(zip(gradients, training_model.trainable_weights))\n",
        "\n",
        "    train_loss(loss)\n",
        "    train_accuracy(accuracy)\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    train_loss.reset_states()\n",
        "    train_accuracy.reset_states()\n",
        "\n",
        "    print(\"\\nStart of epoch %d\" % (epoch + 1))\n",
        "\n",
        "    start_time = time()\n",
        "\n",
        "    # Iterate over the dataset batches\n",
        "    for step, (train_batchX, train_batchY) in enumerate(train_dataset):\n",
        "\n",
        "        # Define the encoder and decoder inputs, and the decoder output\n",
        "        encoder_input = train_batchX[:, 1:]\n",
        "        decoder_input = train_batchY[:, :-1]\n",
        "        decoder_output = train_batchY[:, 1:]\n",
        "\n",
        "        train_step(encoder_input, decoder_input, decoder_output)\n",
        "\n",
        "        if step % 50 == 0:\n",
        "            print(f'Epoch {epoch + 1} Step {step} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\n",
        "            # print(\"Samples so far: %s\" % ((step + 1) * batch_size))\n",
        "\n",
        "    # Print epoch number and loss value at the end of every epoch\n",
        "    print(\"Epoch %d: Training Loss %.4f, Training Accuracy %.4f\" % (epoch + 1, train_loss.result(), train_accuracy.result()))\n",
        "\n",
        "    # Save a checkpoint after every five epochs\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        save_path = ckpt_manager.save()\n",
        "        print(\"Saved checkpoint at epoch %d\" % (epoch + 1))\n",
        "\n",
        "print()\n",
        "print(\"Total time taken: %.2fs\" % (time() - start_time))\n"
      ]
    }
  ]
}